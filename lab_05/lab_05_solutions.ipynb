{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numpy: selected advanced features & simple plotting\n",
    "\n",
    "Szymon Talaga | 13.12.2019\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy and matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# Jupyter notebook directive for showing plots within chunks' output blocks\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Configure IPython shell to show print all outputs generated in a code cell\n",
    "### --------------------------------------------------------------------------\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Special values and array comparisons\n",
    "\n",
    "Numpy define several special values that allow us to deal with mathematical operations resulting in infinites or undefined results.\n",
    "\n",
    "Positive infinity is represented with special value `np.inf`, negative infinity just with its negation `-np.inf`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "7 / 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerator = np.array([1, 2, 3])\n",
    "denominator = np.array([1, 0, 1])\n",
    "\n",
    "numerator / denominator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see, division by zero does not raise an error in Numpy. Instead it creates an infinite value, which is consistent with the two following basic mathematical facts:\n",
    "\n",
    "$$\\lim_{x \\to 0} \\frac{1}{x} = \\infty$$\n",
    "$$\\lim_{x \\to \\infty} \\frac{1}{x} = 0$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graphically, this means:\n",
    "X = np.linspace(0.1, 10, 100)\n",
    "_ = plt.plot(X, 1 / X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy infinites are useful and nice, because they still allow us to compute (they are treated just as very, very large/small numbers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "432 / np.inf\n",
    "0.00000000000000001 * np.inf\n",
    "0 * np.inf\n",
    "np.array([0]) / np.array([0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, results of some mathematical operations can not be determined that easily. For instance,\n",
    "\n",
    "$$\\frac{0}{0}$$\n",
    "\n",
    "does not really have any proper meaning, as the numerator is non-existant, while the denominator tries to make it infinitely large.\n",
    "\n",
    "To represent this kind of an operation Numpy uses a special value `np.nan` (not-a-number)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerator = np.array([1, 0, 3])\n",
    "denominator = np.array([1, 0, 1])\n",
    "\n",
    "numerator / denominator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The special feature of `np.nan` is that it _destroys_ every computation. Any computation including even a single `np.nan` value will always yield `np.nan` as a result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(7 * np.nan)\n",
    "print(np.log(np.nan))\n",
    "print(0 / np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To detect values such as `np.inf` and `np.nan` we use special (vectorized) functions such as `np.isfinite`, `np.isinf` and `np.isnan`.\n",
    "\n",
    "**IMPORTANT.** `np.nan` and `np.inf` are always treated as floating-point numbers. So any array that contain them will be implicitly converted to float `dtype`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([np.inf, -np.inf, np.nan, 1])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if values are finite\n",
    "np.isfinite(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if value are infinite\n",
    "np.isinf(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if value is nan\n",
    "np.isnan(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.\n",
    "\n",
    "You are provided with scores from two exams for a group of 10 students. You need to compute ratios of those scores (exam 2 / exam 1).\n",
    "\n",
    "The problem is that some students may have zero points (if they missed an exam).\n",
    "\n",
    "Then, define three variables:\n",
    "\n",
    "* `G_both` : an array with grades for students who took both exams.\n",
    "* `G1` : an array with grades for students who took only the first exam.\n",
    "* `G2` : an array with grades for students who took only the second exam.\n",
    "* `G_none` : an array with grades for students who did not take any of the exams.\n",
    "\n",
    "You will have to do this in two different ways.\n",
    "\n",
    "1. Use a boolean mask\n",
    "2. Use a 1D array of ratios of grades and use it to calculate boolean masks filtering specific rows.\n",
    "\n",
    "HINT. When using ratios you should base your solution on `np.isfinite`, `np.isinf` and `np.isnan`.\n",
    "\n",
    "HINT 2. Remeber that you can access columns of the grade array like this `G[:, 0]` or `G[:, 1]`.\n",
    "\n",
    "**NOTE.** In any practical setting one should rather always use the more standard approach based on boolean masks and not on calculating ratios first. We do that here only as an exercise on working with NaN and Inf values. The ratio-based solution may also generate quite a bit of different RuntimeWarnings. Do not worry about this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = np.array([\n",
    "    [2.2, 5.],\n",
    "    [0, 7.7],\n",
    "    [6., 9.9],\n",
    "    [0, 0],\n",
    "    [10, 0],\n",
    "    [4, 3.3],\n",
    "    [5, 0],\n",
    "    [0, 9.9],\n",
    "    [1, 3.4],\n",
    "    [0, 8.1]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define variables\n",
    "# ----------------\n",
    "# Use boolean mask\n",
    "G_both = G[G.prod(axis=1) > 0]\n",
    "G1 = G[(G[:, 0] > 0) & (G[:, 1] == 0)]\n",
    "G2 = G[(G[:, 0] == 0) & (G[:, 1] > 0)]\n",
    "G_none = G[G.sum(axis=1) == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define variables\n",
    "# ----------------\n",
    "# Use ratios\n",
    "R = G[:, 1] / G[:, 0]\n",
    "R\n",
    "\n",
    "G_both = G[(~np.isnan(R)) & np.isfinite(R) & (R > 0)]\n",
    "G1 = G[R == 0]\n",
    "G2 = G[(~np.isnan(R)) & (~np.isfinite(R))]\n",
    "G_none = G[np.isnan(R)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aggregation functions working with NaN values\n",
    "\n",
    "A useful feature of Numpy is that it provides all aggregation functions in versions that ignore `np.nan` values. These functions are not defined as methods on arrays but as functions within the Numpy package. So we have the following `nan`-compatible aggregations (and more):\n",
    "\n",
    "* `np.nansum`\n",
    "* `np.nanprod`\n",
    "* `np.nanmean`\n",
    "* `np.nanvar`\n",
    "* `np.nanstd`\n",
    "* `np.nanmin`\n",
    "* `np.nanmax`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.array([\n",
    "    [1, 0, np.nan],\n",
    "    [2, np.nan, 7] \n",
    "])\n",
    "\n",
    "print(X.sum(0))\n",
    "print(np.nansum(X, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Absolute values & array comparisons\n",
    "\n",
    "We know that logical operators in Numpy are vectorized. That is, if we want to test full equality between two different arrays we have to use something else than standard equality operator `==`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([1, 2, 3, 4, 5])\n",
    "Y = np.array([1, 2, 3, 4, 5])\n",
    "\n",
    "X == Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive way\n",
    "(X == Y).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why the approach above is not really good? It is so, because it tests strict equality and will not work properly for floating point numbers, since we know that they have only limited precision and sometimes may represent the same number in two different ways (as two slightly different numbers). We have already seen an example of this, when we standardized variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-standardized variable\n",
    "np.random.seed(103)\n",
    "X = np.random.normal(100, 15, (100, ))\n",
    "# Z-score\n",
    "Z = (X - X.mean()) / X.std()\n",
    "\n",
    "print(Z.mean())\n",
    "print(Z.std())\n",
    "\n",
    "# Testing does not work\n",
    "print(Z.mean() == 0)\n",
    "print(Z.std() == 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is why, when working with floats, it is better to conduct equality tests with some (very small) margin of error.\n",
    "\n",
    "For this, we can use `np.abs` function that computes absolute value (turns negative numbers to their positive counterparts).\n",
    "\n",
    "With a function like that we can define equality test by checking wheter an absolute difference between two numbers is very, very small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test whether mean of Z variable is zero\n",
    "np.abs(Z.mean() - 0) < 10**-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test whether standard deviation of Z variables is one\n",
    "np.abs(Z.std() - 1) < 10**-9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is nice, but quite verbose and sometimes it may not be easy to deduce the true meaning of an expression like that from the context.\n",
    "Luckily, Numpy provides a utility function for making approximate comparisons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.isclose(Z.mean(), 0, rtol=10**-9) # rtol specifies tolerance of a comparion\n",
    "np.isclose(Z.std(), 1)  # but rtol has a reasonable default value, so we do not have to specify it all the time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For arrays we may do\n",
    "X = np.array([.1, .2]) \n",
    "Y = np.array([.1+10**-12, .2])\n",
    "\n",
    "np.isclose(X, Y).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, both logical operators and `np.isclose` are vectorized, so they may be used to compare arrays with different shapes according to the rules of broadcasting. Thus, we may test equality between arrays of different shape. If we want to be sure that arrays have the same shape and the same values we may use `np.array_equal`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([1, 2, 3])\n",
    "Y = np.array([1, 2, 3])\n",
    "Y2 = Y[None, :]\n",
    "\n",
    "print(np.array_equal(X, Y))\n",
    "print(np.array_equal(X, Y2))\n",
    "print((X == Y2).all())\n",
    "\n",
    "np.isclose(X, Y).all() and X.shape == Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([1, 1])\n",
    "Y = np.array([1])\n",
    "\n",
    "np.isclose(X, Y).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2.\n",
    "\n",
    "You are provided with three simple arrays, which are equal (up to floating-point precision). However, `X` and `Y` have exactly the same shape while `Z` has a different but broadcastable shape.\n",
    "\n",
    "Write two different expressions, one which will return `True` for comparison between all three arrays, and one which will return `False` for comparisons including `Z` (so it has to detect that it has different shape)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.uniform(0, 1, (4, 2))\n",
    "Y = X.copy()\n",
    "Y[2, 0] += 10**-12\n",
    "Z = Y[None, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "\n",
    "# Expression 1 (written as lambda functions so it can be reused)\n",
    "compare1 = lambda x, y: np.isclose(x, y).all()\n",
    "\n",
    "compare1(X, Y)\n",
    "compare1(Y, Z)\n",
    "\n",
    "# Expression 2\n",
    "compare2 = lambda x, y: np.isclose(x, y).all() and x.shape == y.shape\n",
    "\n",
    "compare2(X, Y)\n",
    "compare2(Y, Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE.** In the exercise above we used the following expression: `Y[None, ...]`. We know the meaning of ``None`` in the context of indexing. However, what does the ellipsis (`...`) mean?\n",
    "\n",
    "Ellipsis is a special symbol used in the context of array indexing in Numpy and it just means \"get everything along the remaining axes\".\n",
    "\n",
    "So in our case we have that:\n",
    "\n",
    "```python\n",
    "Y[None, ...]\n",
    "# Is equivalent to:\n",
    "Y[None, :, :]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing utilities, array conditionals & array concatenation\n",
    "\n",
    "In this section we review some of the utility functions provided by Numpy which allow us execute some more advanced array manipulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1111)\n",
    "X = np.random.randint(0, 5, (5, 3))\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get indices of non-zero elements\n",
    "np.where(X)\n",
    "# Equvalent to\n",
    "np.nonzero(X)\n",
    "# Equivalent to\n",
    "X.nonzero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([\n",
    "    [1, 0],\n",
    "    [0, 0],\n",
    "    [1, 0]\n",
    "])\n",
    "X.nonzero()\n",
    "X[X.nonzero()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use output of these commands to extract non-zero elements.\n",
    "X[X.nonzero()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get an array of indices of non-zero elements\n",
    "np.argwhere(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we can use this functions to get indices of elements satisfying any condition just by turning our array to a boolean mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(101010)\n",
    "X = np.random.normal(100, 15, (100,))\n",
    "(X > 130).nonzero()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also ask for indices of elements with maximum/minimum values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([1, 0, 3, 5, 2])\n",
    "print(np.argmin(X))\n",
    "print(np.argmax(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also look for minima/maxima along specific axes (like with aggregating functions). Moreover, `argmin` and `argmax` are also defined as methods on arrays like other aggregating functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([\n",
    "    [0, 1, 2],\n",
    "    [3, 1, 4],\n",
    "    [3, 3, 5],\n",
    "    [0, 5, 1]\n",
    "])\n",
    "print(X.argmin(1))\n",
    "print(X.argmax(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE.** `argmax` and `argmin` function will return indices for only first occurences of minimal/maximal values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.\n",
    "\n",
    "You have 1000 replications of 10 relizations of standard random normal variables (mean 0 and standard deviation 1) arranged as 1000-by-10 array.\n",
    "\n",
    "Your task is to compute a vector of differences between highest and lowest values for each replication (row).\n",
    "\n",
    "Then compute its minimum, maximum and mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HINT. There are at least two possible solutions. However, you will have to use either `argmin` / `argmax` or `min` / `max` aggregation methods.\n",
    "\n",
    "HINT 2. Remeber that you can check shape of an array with `.shape` attribute. For instance (`X.shape[0]`) gives you number of elements along the first axis of an array `X`.\n",
    "\n",
    "HINT 3. There are two fundamental approaches to this problem. In one of them you will have to use integer indexing, and in the other boolean mask (and also non-trivial broadcasting)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1030)\n",
    "X = np.random.normal(0, 1, (1000, 10))\n",
    "X "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code\n",
    "diff = X[np.arange(X.shape[0]), X.argmax(axis=1)] - X[np.arange(X.shape[0]), X.argmin(axis=1)]\n",
    "(diff.min(), diff.max(), diff.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Array conditionals (`np.where`)\n",
    "\n",
    "Numpy provides a sort of vectorized if-else statement. It is implemented in `np.where` command. When called with only one argument `np.where` is equivalent to `np.nonzero`. However, it can be also called in a different way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.arange(25)\n",
    "# Change even numbers to -1 and odd numbers to 1\n",
    "X\n",
    "np.where(X % 2 == 0, -1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The signature in this case is the following:\n",
    "\n",
    "1. Boolean mask.\n",
    "2. Value when `True`.\n",
    "3. Value when `False`.\n",
    "\n",
    "Crucially, values for `True` and `False` can be arrays (broadcastable to the shape of the mask)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.arange(25).reshape(5, 5)\n",
    "np.where(X > 10, \"a\", X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4.\n",
    "\n",
    "You are provided with numerical data arranged in column (one variable per column; one observation per row).\n",
    "However, some data is missing and flagged with special value `-9999`.\n",
    "\n",
    "Your task is to impute (substitute) missing data.\n",
    "\n",
    "There are multiple ways to do this, but here try to use `np.where`.\n",
    "\n",
    "HINT. You may want to use the special `np.nan` value and the `np.nanmean` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([\n",
    "    [   95.08366696, -9999.        ,   150.12629188],\n",
    "    [   89.87133854,    87.9538498 , -9999.        ],\n",
    "    [   66.94088651,    89.10385855,   148.30490322],\n",
    "    [   91.8650191 ,    92.48798628,   131.62206329],\n",
    "    [   93.67604461,   108.72757053,   101.51671987],\n",
    "    [   72.46685745,   101.13977638,   109.58983797],\n",
    "    [-9999.        ,    74.48208296,   102.33482566],\n",
    "    [   85.98488673,   101.45699029, -9999.        ],\n",
    "    [   62.42395255,    90.12892136,   146.23682339],\n",
    "    [-9999.        ,   117.53133364,   116.633318  ],\n",
    "    [   84.52842147,   114.09702542,   115.53127904],\n",
    "    [   93.38194876,    92.37845489,   115.16915058],\n",
    "    [   90.91462244,    92.22887186, -9999.        ],\n",
    "    [   92.28042609,    93.95893253,    79.68687896],\n",
    "    [  105.03852103,    89.65620823,   105.64447664],\n",
    "    [   97.44807231,    91.54461761,   130.27602515],\n",
    "    [   77.97303996,    87.46745456,    88.56068159],\n",
    "    [   77.23304387, -9999.        ,   103.98638999],\n",
    "    [   78.81684918,    91.75194925,    86.1878638 ],\n",
    "    [   78.40007596, -9999.        ,   109.96346709]\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part A**\n",
    "\n",
    "Impute missing data with column means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code\n",
    "X[X == -9999] = np.nan\n",
    "np.where(np.isnan(X), np.nanmean(X, axis=0), X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part B**\n",
    "\n",
    "Impute missing data with row means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code\n",
    "np.where(np.isnan(X), np.nanmean(X, axis=1)[:, None], X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concatenating arrays\n",
    "\n",
    "Array concatenation is a process of joining arrays either side by side or by stacking them one on top of another. In general they may be _glued_ along any of the axes.\n",
    "\n",
    "\n",
    "```python\n",
    "# Horizontal concatenation\n",
    "# -----------------------------\n",
    "x x x     x x x     x x x x x x\n",
    "x x x  +  x x x  =  x x x x x x\n",
    "x x x     x x x     x x x x x x\n",
    "\n",
    "# Vertical concatenation\n",
    "# -----------------------------\n",
    "          x x x x x\n",
    "          x x x x x\n",
    "\n",
    "              +\n",
    "\n",
    "          x x x x x\n",
    "          x x x x x\n",
    "\n",
    "              =\n",
    "\n",
    "          x x x x x\n",
    "          x x x x x\n",
    "          x x x x x\n",
    "          x x x x x\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.ones((5, 3), dtype=int)\n",
    "Y = np.zeros((5, 3), dtype=int)\n",
    "\n",
    "print(X)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.concatenate([X, Y], axis=0)  # vertical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.concatenate([X, Y], axis=1)  # horizontal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Flattening\n",
    "\n",
    "Any multidimensional array can be always flattened to a 1D array with `flatten` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.arange(9).reshape(3, 3)\n",
    "X\n",
    "X.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5\n",
    "\n",
    "You have a set of variables that you want to use as predictors in a regression model.\n",
    "First, however, you need to build a design matrix in which the first column is filled with ones,\n",
    "since you want to include an intercept term in your model.\n",
    "\n",
    "Thus, you need to build an array with the following structure:\n",
    "\n",
    "$$\\left[\\quad 1 \\quad X \\quad\\right]$$\n",
    "\n",
    "Where $X$ is and array with $n$ predictors and $1$ is a single column filled with ones.\n",
    "\n",
    "HINT. Remember that shapes have to be broadcastable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictors (one per column)\n",
    "X = np.random.normal(10, 2, (10, 3))\n",
    "\n",
    "# Your code\n",
    "np.concatenate((np.ones((X.shape[0], 1)), X), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple plotting\n",
    "\n",
    "The most popular (although perhaps not the best) plotting package in scientific Python is `matplotlib`.\n",
    "It is very well integrated with `numpy` and most people use it as a default visualization software for Python.\n",
    "We will discuss it in more detail in the end of the course. Here, we review only a few basic functionalities.\n",
    "\n",
    "The most basic (but not the best) way to work with `matplotlib` is to work directly with `pyplot` engine.\n",
    "Later we will discuss better ways of interacting with `matplotlib`.\n",
    "\n",
    "However, regardless of particular approach, the general mechanics of plotting are (almost) always the same.\n",
    "You have to specify coordinates of points and define plotting operations for visualizing these points as well as specify aesthetic details such as color, size, point markers etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# Jupyter notebook directive for showing plots within chunks' output blocks\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Line plots\n",
    "\n",
    "Line plot is perhaps the simplest kind of graph there is. It is defined by an ordered sequence of data points connected by a (straight) line.\n",
    "Of course, if points are very densely packed it can be used to visualize even very non-linear patterns of mathematical function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a graph of a simple linear function that we all know from school and understand very well (right?):\n",
    "\n",
    "$$f(x) = 2x + 5$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate values for independent variable `x`\n",
    "X = np.array([-5, 5])\n",
    "Y = 2*X + 5\n",
    "\n",
    "_ = plt.plot(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was simple linear function, so two `x` values were enough. However, with more nonlinear function you have to provide a dense grid to get a proper plot.\n",
    "\n",
    "Below we show plots of:\n",
    "\n",
    "$$f(x) = \\sin(x)$$\n",
    "$$g(x) = \\cos(x)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Too sparse a grid of values for X\n",
    "X_sparse = np.linspace(-5, 5, 10)\n",
    "\n",
    "_ = plt.plot(X_sparse, np.sin(X_sparse))\n",
    "_ = plt.plot(X_sparse, np.cos(X_sparse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proper, dense grid of values for X\n",
    "X_dense = np.linspace(-5, 5, 1000)\n",
    "\n",
    "_ = plt.plot(X_dense, np.sin(X_dense), label='sine')\n",
    "_ = plt.plot(X_dense, np.cos(X_dense), label='cosine')\n",
    "_ = plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that here we have two calls to `pyplot` which draw two data series on the same plot.\n",
    "We use `label` argument to assign names to them, which we then can use to easily generate a simple legend."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6. Probability density function of standard normal distribution\n",
    "\n",
    "Standard normal distribution has the following probability density function:\n",
    "\n",
    "$$p(x) = \\frac{1}{\\sqrt{2\\pi}}e^{-\\frac{1}{2}x^2}$$\n",
    "\n",
    "Plot it. What would be a reasonable range of value of x (support) in this case?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code\n",
    "X = np.linspace(-5, 5, 1000)\n",
    "Y = (1 / np.sqrt(2*np.pi)) * np.exp(-1/2*X**2)\n",
    "\n",
    "_ = plt.plot(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scatter plots\n",
    "\n",
    "The second most fundamental type of plot is a scatter plot that shows points on a plane."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(700)\n",
    "\n",
    "X1, Y1 = np.random.normal(10, 2, (20,)), np.random.normal(8, 2.2, (20,))\n",
    "X2, Y2 = np.random.normal(20, 4, (30,)), np.random.normal(12, 3, (30,))\n",
    "\n",
    "_ = plt.scatter(X1, Y1)\n",
    "_ = plt.scatter(X2, Y2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 7\n",
    "\n",
    "(It is similar to one of the previous exercises)\n",
    "\n",
    "You have two landmark points and a set of other points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Landmarks\n",
    "L = np.array([\n",
    "    [10., 8.],\n",
    "    [21., 14.]\n",
    "])\n",
    "\n",
    "# Other points\n",
    "X = np.array([\n",
    "   [10.65537532, 11.75553032, 10.2438015 , 11.27617932, 10.92449282,  8.33898956,  7.12060104,  7.91033838,  8.66976065, 12.13338894,\n",
    "     8.34090356, 10.71625218,  6.86878097,  9.75949972,  6.40542673, 10.40846816, 12.7694654 ,  8.82783884,  8.46280746, 10.90185464,\n",
    "    25.85252142, 18.86690838, 12.88488671, 19.94256508, 17.76185212, 23.78767291, 18.33303976, 20.90630389, 18.48326826, 18.86998929,\n",
    "    18.65390626, 25.69099097, 17.15384067, 21.024908  , 12.15796957, 19.24130486, 16.95384124, 20.29053166, 20.54089591, 22.87006511,\n",
    "    18.98676712, 14.95420311, 14.56084402, 21.78222637, 26.40008116, 15.39072287, 18.12252204, 21.88134108, 19.728441  , 19.76442387], \n",
    "   [ 6.80590341, 12.4593391 ,  8.63999522,  6.33398434,  6.28210219, 11.69316112,  9.29975522,  7.48038945,  4.48924088,  6.7358552 ,\n",
    "    10.7618582 ,  4.7551169 , 11.00008083,  9.65007903,  6.24194341, 10.62440694,  1.69655994,  8.77677847,  8.29581413,  9.48440063,\n",
    "     7.53965525, 14.00299918, 17.0873315 , 10.19568997, 12.94790368, 14.48475401, 11.86610136, 11.95326815, 12.9925746 , 15.67964003,\n",
    "    10.91753477, 11.99621723,  8.09633454, 11.21578731, 10.83314594, 11.2225141 , 10.99995258, 15.87136058,  8.82076652, 11.64945052,\n",
    "    13.06093943, 15.92770303, 13.65828605, 14.42156552, 11.4700492 ,  8.27349555,  9.03039074,  9.34838708,  7.37074819, 11.25353002]\n",
    "]).T\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.scatter(X[:, 0], X[:, 1], label='points')\n",
    "_ = plt.scatter(L[:, 0], L[:, 1], label='landmarks', s=200)\n",
    "_ = plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recreate the above plot but in such a way that points which are closer to the first landmark have different color than points closer to the second landmark.\n",
    "\n",
    "Remember that (Euclidean) distance in 2D is:\n",
    "\n",
    "$$d(\\text{point}_i, \\text{point}_j) = \\sqrt{(x_i - x_j)^2 + (y_i - y_j)^2}$$\n",
    "\n",
    "HINT. Remember that in Numpy to negate a boolean array we use `~` unary operator; for instance `~X`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code\n",
    "# -----------\n",
    "# Distances from landmarks per point\n",
    "D = np.sqrt(((X[:, None, :] - L)**2).sum(axis=-1))\n",
    "# Which landmark is closer\n",
    "I = np.argmin(D, axis=1)\n",
    "\n",
    "_ = plt.scatter(X[I == 0, 0], X[I == 0, 1], label='landmark 1 neighbourhood', c='red')\n",
    "_ = plt.scatter(X[I == 1, 0], X[I == 1, 1], label='landmark 2 neighbourhood', c='blue')\n",
    "_ = plt.scatter(L[:, 0], L[:, 1], c='orange', s=200)\n",
    "_ = plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating random numbers\n",
    "\n",
    "Remeber, computers never generate anything truly random. The only randomness we can get is pseudorandomness, which is generated by algorithms which are chaotic in a sense that they give very different outputs even for very similar inputs. Hence, if they are seeded with input values that depend on many things that are independent from our application (i.e. internal clock of the CPU), then they can generate data that looks random enough for most intents and purposes.\n",
    "\n",
    "At the same time, this non-randomness can be usefull because if we ran the same algorithm with the same seed we are guaranteed to get the same result. Thus, by setting random seed we can ensure that our results will be replicated.\n",
    "\n",
    "Everything related to random numbers generation in Numpy is implemented in `random` module.\n",
    "\n",
    "Random numbers are generated with functions provided by `random` module. In general all the functions have similar signatures:\n",
    "\n",
    "* First they take arguments defining parameters of a probability distribution that will be used (for instance mean and standard deviation for normal distribution)\n",
    "* Then they take a shape tuple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed\n",
    "np.random.seed(10101)\n",
    "\n",
    "# Generate random uniform: <from>, <to>, <shape>\n",
    "_ = plt.hist(np.random.uniform(0, 1, (1000,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate normal: <mean>, <standard deviation>, <shape>\n",
    "_ = plt.hist(np.random.normal(0, 1, (1000,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate uniform integers: <from>, <to>, <shape>\n",
    "_ = plt.hist(np.random.randint(0, 5, (1000,)), bins=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate from t distribtution: <df>, <shape>\n",
    "_ = plt.hist(np.random.standard_t(5, (1000,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate from log-normal distribution: <mean>, <standard deviation>, <shape>\n",
    "_ = plt.hist(np.random.lognormal(5, 1, (1000,)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also sample random values from a predefined set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = ['N', 'E', 'S', 'W']\n",
    "# Sample 10 times with replacement\n",
    "np.random.choice(values, 10, replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample 2 times without replacement\n",
    "np.random.choice(values, 2, replace=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 8.\n",
    "\n",
    "In this exercise we will estimate the value of $\\pi$ using numerical methods (a simple Monte Carlo simulation).\n",
    "\n",
    "The setup is simple. We know that the volume of a circle is:\n",
    "\n",
    "$$\\pi r^2$$\n",
    "\n",
    "So if $r = 1$ the volume is just $\\pi$.\n",
    "\n",
    "On the other hand the equation of a circle (with $r = 1$) is:\n",
    "\n",
    "$$1 = x^2 + y^2 \\Rightarrow y = \\sqrt{1 - x^2}$$\n",
    "\n",
    "Therefore we can simulate random number uniformly within a unit square (very many such numbers) and check how often they land below the graph of $\\sqrt{1 - x^2}$.\n",
    "This will give us $\\frac{1}{4}\\pi$.\n",
    "\n",
    "HINT. You will have to test $x^2 + y^2 <= 1$\n",
    "\n",
    "HINT 2. Remember that the number of random samples your draw will affect the accuracy of your approximation.\n",
    "\n",
    "![Monte Carlo estimation of pi](monte-carlo-pi.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code\n",
    "X = np.random.uniform(0, 1, (500000, 2))\n",
    "((X**2).sum(axis=1) <= 1).mean() * 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accumulators\n",
    "\n",
    "Sometimes we may want to accumulate some values instead of aggregating them into a single thing. There are two main accumulators implemented in Numpy:\n",
    "\n",
    "* `cumsum` (cumulative sum)\n",
    "* `cumprod` (cumulative product)\n",
    "\n",
    "Cumulative sum may be useful for instance to compute and study random walks. Random walk is a process in which we sample random values from some distribution (i.e. standard normal) at each time step and we accumulate generated values. In other words, at each step we start from the position in which we ended after the previous step and we move forward or backward by some random amount.\n",
    "\n",
    "In one dimension this can be defined as follows:\n",
    "\n",
    "$$x_0 = 0$$\n",
    "$$x_{n+1} = x_n + X_{n+1}$$\n",
    "$$X_i \\sim \\mathcal{N}(0, 1)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(303)\n",
    "X = np.random.normal(0, 1, (1000,))\n",
    "\n",
    "_ = plt.plot(X.cumsum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random walks are very interesting when looked at from the perspective of the final position (after $n$) steps.\n",
    "\n",
    "In out setting we know that $\\mathbb{E}[X] = 0$. And we know that $x_n = 0 + X_1 + X_2 + \\ldots + X_n$. Thus:\n",
    "\n",
    "$$\\mathbb{E}[x_n] = 0 + \\mathbb{E}[X_1] + \\mathbb{E}[X_2] + \\ldots + \\mathbb{E}[X_n] = 0 + 0 + 0 + \\ldots + 0 = 0$$\n",
    "\n",
    "However, since random innovation at each step ($X_i$) are independent, the variance of the process grows in a manner which is easy to predict:\n",
    "\n",
    "$$\\text{Var}(x_n) = \\sum_{i=1}^n \\text{Var}(X_i) = n$$\n",
    "\n",
    "So as the walk becomes longer and longer we get:\n",
    "\n",
    "$$\\lim_{n \\to \\infty}\\text{Var}(x_n) = \\lim_{n \\to \\infty}n = \\infty$$\n",
    "\n",
    "In other words variance of the process becomes infinite. This means that in the long run we can never predict where the random walk will end. And this unpredictability is completely unbiased as on average we remain in the very place we started from."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 9.\n",
    "\n",
    "Plot 100 random walks of length 500 to really see the above result.\n",
    "\n",
    "Then plot 100 random walks of length 5000 and check how the range of $y$ values changed.\n",
    "\n",
    "HINT. In this exercise you will **have to use a for-loop** (to draw random walks)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code | plot 1\n",
    "X = np.random.normal(0, 1, (500,)).cumsum()\n",
    "_ = plt.plot(X)\n",
    "X.max() - X.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code | plot 2\n",
    "X = np.random.normal(0, 1, (5000,)).cumsum()\n",
    "_ = plt.plot(X)\n",
    "X.max() - X.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization\n",
    "\n",
    "Optimization is a process of finding minima or maxima of a function of one or many parameters. Since this is a calculus-free class we will discuss only one gradient-free optimization algorithm,\n",
    "the [Nelder-Mead](https://en.wikipedia.org/wiki/Nelder%E2%80%93Mead_method) method.\n",
    "\n",
    "Optimization methods are implemented in `scipy` package which is a sibling on Numpy that provides many more advanced tools for scientific computing.\n",
    "\n",
    "The Nelder-Mead method as implemented in `scipy` can be used only to find minima and not maxima.\n",
    "\n",
    "Below we find the minimum of a simple quadratic function: $y = x^2 + 3x + 5$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.linspace(-10, 10)\n",
    "\n",
    "def f(X):\n",
    "    return X**2 + 3*X + 5\n",
    "\n",
    "_ = plt.plot(X, f(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "# We have to provide a starting value\n",
    "# This is something one has to do almost\n",
    "# always when using numerical optimization\n",
    "# routines.\n",
    "#\n",
    "# In the general case it is important\n",
    "# that a starting value has to be in the\n",
    "# domain of the function and the closer\n",
    "# it approximates the solution the better,\n",
    "# so if we can make an educated guess\n",
    "# about the solution, then we should use it.\n",
    "\n",
    "x0 = -1\n",
    "solution = minimize(f, x0, method=\"Nelder-Mead\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get x value that minimizes f(x)\n",
    "x_min = solution.x\n",
    "x_min, f(x_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.plot(X, f(X))\n",
    "_ = plt.scatter(x_min, f(x_min), marker=\"*\", s=500, c='r', zorder=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, that (almost) all optimization routines of this kind find only a single local optimum. This is not a problem when our function has only one global optimum, but when we have more than one we have to be cautious and check whether a solution we get makes sense. This is sometimes easy, but usually rather hard. In general, the problem is that our solution will depend on a starting value we provide an algorithm with.\n",
    "\n",
    "Below we study the simplest case of a function with two different minima, a 4rd degree polynomial (quartic polynomial):\n",
    "\n",
    "$$f(x) = x^4 + x^3 - 2x^2 - 2x + 1$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.linspace(-2, 2, 1000)\n",
    "\n",
    "def f(X):\n",
    "    return X**4 + X**3 - 2*X**2 - 2*X + 1\n",
    "\n",
    "_ = plt.plot(X, f(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0_1 = -0.5\n",
    "x0_2 =  0.5\n",
    "\n",
    "sol1 = minimize(f, x0_1, method='Nelder-Mead').x\n",
    "sol2 = minimize(f, x0_2, method='Nelder-Mead').x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.plot(X, f(X))\n",
    "_ = plt.scatter(x0_1, f(x0_1), marker=\"<\", s=200, c='r', zorder=5)\n",
    "_ = plt.scatter(sol1, f(sol1), marker=\"*\", s=500, c='r', zorder=5)\n",
    "_ = plt.scatter(x0_2, f(x0_2), marker=\">\", s=200, c='g', zorder=5)\n",
    "_ = plt.scatter(sol2, f(sol2), marker=\"*\", s=500, c='g', zorder=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use Nelder-Mead method also to optimize functions with many arguments. Below we show an example of maximization of a 2D quadratic function.\n",
    "\n",
    "$$f(x, y) = -x^2 + -y^2 + xy + x + y + 10$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.linspace(-5, 5, 100)\n",
    "Y = np.linspace(-5, 5, 100)\n",
    "XY = np.meshgrid(X, Y)\n",
    "\n",
    "def f(XY):\n",
    "    X, Y = XY\n",
    "    return -X**2 + -Y**2 + X*Y + X + Y + 10\n",
    "\n",
    "cp = plt.contourf(*XY, f(XY))\n",
    "_ = plt.colorbar(cp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = np.array([0., 0.])\n",
    "\n",
    "sol = minimize(f, x0, method='Nelder-Mead')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that for Nelder-Mead method to work the function that we want to optimize has to be defined in a specific way. It still has to take only one argument and only within the function it can be unpacked and divided into multiple parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp = plt.contourf(*XY, f(XY))\n",
    "_ = plt.colorbar(cp)\n",
    "_ = plt.scatter(sol.x[0], sol.x[1], marker='*', s=500, c='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Something is off. We forgot that the Nelder-Mead method can only minimize. So it did not find the optimum maximum, but instead it tried to minimize and the function has diverging minimum. However, we can easily fix this. It is enough that we redefine our function, so it returns negative values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neg_f(XY):\n",
    "    return -f(XY)\n",
    "\n",
    "sol = minimize(neg_f, x0, method='Nelder-Mead')\n",
    "\n",
    "cp = plt.contourf(*XY, f(XY))\n",
    "_ = plt.colorbar(cp)\n",
    "_ = plt.scatter(sol.x[0], sol.x[1], marker='*', s=500, c='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 10.\n",
    "\n",
    "Find all optima (minima and maxima) of the following function of two variables:\n",
    "\n",
    "$$f(x, y) = \\frac{xy - x + y}{x^2 + y^2 + 0.4}$$\n",
    "\n",
    "Visualize your solution by drawing a contour plot with optima marked with stars.\n",
    "\n",
    "HINT. First visualize the function and look at it carefully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code | visualize function\n",
    "def f(XY):\n",
    "    X, Y = XY\n",
    "    return (X*Y - X + Y) / (X**2 + Y**2 + 0.4)\n",
    "\n",
    "X = np.linspace(-8, 8, 100)\n",
    "Y = np.linspace(-8, 8, 100)\n",
    "XY = np.meshgrid(X, Y)\n",
    "\n",
    "cp = plt.contourf(*XY, f(XY))\n",
    "_ = plt.colorbar(cp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code | find optima and plot them\n",
    "x0 = np.array([0, 0])\n",
    "\n",
    "solution_min = minimize(f, x0, method='Nelder-Mead')\n",
    "solution_max = minimize(lambda xy: -f(xy), x0, method='Nelder-Mead')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp = plt.contourf(*XY, f(XY))\n",
    "_ = plt.colorbar(cp)\n",
    "_ = plt.scatter(solution_min.x[0], solution_min.x[1], marker='*', s=200, c='r')\n",
    "_ = plt.scatter(solution_max.x[0], solution_max.x[1], marker='*', s=200, c='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
